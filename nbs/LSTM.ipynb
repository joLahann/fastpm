{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import * \n",
    "from fastai.text import *\n",
    "from exp.eventlog import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse date: 1970-01-01T00:00:00.000+01:00\n",
      "failed to parse date: 1970-01-01T00:00:00.000+01:00\n",
      "failed to parse date: 2012-04-23T00:00:00.000+02:00\n",
      "failed to parse date: 2011-10-01T00:38:44.546+02:00\n",
      "failed to parse date: 2012-03-14T16:04:54.681+01:00\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.BPIC_2012)\n",
    "log = import_xes(path,extensions=False,classifiers=False,schema=False,log_attributes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173688</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173688</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.880000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173688</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-09-30 22:39:37.906000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173688</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 09:36:46.437000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trace_id  event_id org:resource lifecycle:transition  \\\n",
       "0   173688         0          112             COMPLETE   \n",
       "1   173688         1          112             COMPLETE   \n",
       "2   173688         2          112             COMPLETE   \n",
       "3   173688         3          112             SCHEDULE   \n",
       "4   173688         4         None                START   \n",
       "\n",
       "             concept:name                   time:timestamp  \n",
       "0             A_SUBMITTED 2011-09-30 22:38:44.546000+00:00  \n",
       "1       A_PARTLYSUBMITTED 2011-09-30 22:38:44.880000+00:00  \n",
       "2           A_PREACCEPTED 2011-09-30 22:39:37.906000+00:00  \n",
       "3  W_Completeren aanvraag 2011-09-30 22:39:38.875000+00:00  \n",
       "4  W_Completeren aanvraag 2011-10-01 09:36:46.437000+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log.events\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer-encoding the unique values of the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = df['concept:name'].unique()\n",
    "people = df['org:resource'].unique()\n",
    "\n",
    "concepts = tuple(set(activities))\n",
    "int2concept = dict(enumerate(concepts))\n",
    "concept2int = {c: ii for ii, c in int2concept.items()}\n",
    "\n",
    "concepts_enc = np.array([concept2int[c] for c in activities])\n",
    "\n",
    "users = tuple(set(people))\n",
    "int2user = dict(enumerate(users))\n",
    "user2int = {u: ii for ii, u in int2user.items()}\n",
    "\n",
    "users_enc = np.array([user2int[c] for c in people])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 unique values in concept:names.\n",
      "There are 69 unique values in org:resources.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(len(activities)) + \" unique values in concept:names.\")\n",
    "print(\"There are \" + str(len(people)) + \" unique values in org:resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  3, 14,  5, 23, 11, 16, 12,  1, 10,  9, 15, 17,  4,  7, 21, 19,  2, 13,  8,  6, 18, 22,  0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([53, 31, 46, 58, ...,  6, 49, 27, 33])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(concepts_enc)\n",
    "display(users_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the desired column in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier fehlt allerdings leider die Möglichkeit, das ganze wieder zurück encoden zu können. Ich weiss nicht wie man aus den Integern hier wieder die Strings bekommt, oder wo man das dazu gehörige mapping findet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173688</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173688</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-30 22:38:44.880000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173688</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-09-30 22:39:37.906000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173688</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>19</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>START</td>\n",
       "      <td>19</td>\n",
       "      <td>2011-10-01 09:36:46.437000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trace_id  event_id org:resource lifecycle:transition  concept:name  \\\n",
       "0   173688         0          112             COMPLETE             9   \n",
       "1   173688         1          112             COMPLETE             6   \n",
       "2   173688         2          112             COMPLETE             7   \n",
       "3   173688         3          112             SCHEDULE            19   \n",
       "4   173688         4         None                START            19   \n",
       "\n",
       "                    time:timestamp  \n",
       "0 2011-09-30 22:38:44.546000+00:00  \n",
       "1 2011-09-30 22:38:44.880000+00:00  \n",
       "2 2011-09-30 22:39:37.906000+00:00  \n",
       "3 2011-09-30 22:39:38.875000+00:00  \n",
       "4 2011-10-01 09:36:46.437000+00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, levels = pd.factorize(df[\"concept:name\"])\n",
    "\n",
    "df[\"concept:name\"] = df[\"concept:name\"].astype('category')\n",
    "df[\"concept:name\"] = df[\"concept:name\"].cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryProcessor??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traces zusammenfassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, dass alles über einen Trace in einer Zeile steht mit der trace_id als Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert traces generalized\n",
    "def conv_traces(df):\n",
    "    d = {}\n",
    "    for i in df.columns:\n",
    "        d[i] = ' '.join(df[i].map(str))\n",
    "        \n",
    "    return Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>9 6 7 19 19 0 14 5 12 15 21 19 21 21 21 21 21 ...</td>\n",
       "      <td>112 112 112 112 None 10862 10862 10862 10862 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173691</th>\n",
       "      <td>9 6 7 19 19 19 19 0 5 14 12 15 21 19 21 21 21 ...</td>\n",
       "      <td>112 112 112 112 None None None 10862 10862 108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173694</th>\n",
       "      <td>9 6 7 19 19 19 19 19 19 19 19 0 5 14 12 15 21 ...</td>\n",
       "      <td>112 112 112 112 10912 10912 None None 11201 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173697</th>\n",
       "      <td>9 6 4</td>\n",
       "      <td>112 112 112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173700</th>\n",
       "      <td>9 6 4</td>\n",
       "      <td>112 112 112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               concept:name  \\\n",
       "trace_id                                                      \n",
       "173688    9 6 7 19 19 0 14 5 12 15 21 19 21 21 21 21 21 ...   \n",
       "173691    9 6 7 19 19 19 19 0 5 14 12 15 21 19 21 21 21 ...   \n",
       "173694    9 6 7 19 19 19 19 19 19 19 19 0 5 14 12 15 21 ...   \n",
       "173697                                                9 6 4   \n",
       "173700                                                9 6 4   \n",
       "\n",
       "                                               org:resource  \n",
       "trace_id                                                     \n",
       "173688    112 112 112 112 None 10862 10862 10862 10862 1...  \n",
       "173691    112 112 112 112 None None None 10862 10862 108...  \n",
       "173694    112 112 112 112 10912 10912 None None 11201 11...  \n",
       "173697                                          112 112 112  \n",
       "173700                                          112 112 112  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('trace_id')[\"concept:name\", \"org:resource\"].apply(conv_traces)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend werden alle concept:name Werte die aktuell noch in Strings zusammengefasst sind in eine große Liste eingefügt. So bekommt man einen großen Datensatz (/Liste) aller Werte in der Spalte. \n",
    "\n",
    "Hier wäre es sinnvoll am Ende jedes Traces irgendein bestimmtes encodetes Token einzufügen, oder nicht?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 s, sys: 0 ns, total: 49.7 s\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = np.array([])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    data = np.append(data, [df[\"concept:name\"][i].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs * n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    \n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        \n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        \n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(data, 10, 20)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['9', '6', '7', '19', ..., '21', '16', '22', '21'],\n",
       "       ['21', '16', '22', '21', ..., '9', '6', '7', '19'],\n",
       "       ['19', '19', '19', '19', ..., '21', '11', '14', '12'],\n",
       "       ['21', '21', '21', '16', ..., '22', '10', '8', '2'],\n",
       "       ...,\n",
       "       ['17', '17', '4', '17', ..., '5', '14', '12', '15'],\n",
       "       ['20', '22', '20', '20', ..., '20', '20', '20', '20'],\n",
       "       ['16', '22', '21', '22', ..., '19', '0', '14', '5'],\n",
       "       ['7', '19', '19', '0', ..., '21', '21', '21', '21']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['6', '7', '19', '19', ..., '16', '22', '21', '22'],\n",
       "       ['16', '22', '21', '22', ..., '6', '7', '19', '19'],\n",
       "       ['19', '19', '19', '19', ..., '11', '14', '12', '15'],\n",
       "       ['21', '21', '16', '22', ..., '10', '8', '2', '1'],\n",
       "       ...,\n",
       "       ['17', '4', '17', '9', ..., '14', '12', '15', '21'],\n",
       "       ['22', '20', '20', '20', ..., '20', '20', '20', '20'],\n",
       "       ['22', '21', '22', '10', ..., '0', '14', '5', '12'],\n",
       "       ['19', '19', '0', '14', ..., '21', '21', '21', '11']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, n_steps=100, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Creating character dictionaries\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        ## Define the LSTM\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## Define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## Define the final, fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        \n",
    "        # Initialize the weights\n",
    "        self.init_weights()\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hc):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hc`. '''\n",
    "        \n",
    "        ## Get x, and the new hidden state (h, c) from the lstm\n",
    "        x, (h, c) = self.lstm(x, hc)\n",
    "        \n",
    "        ## Ppass x through the dropout layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Stack up LSTM outputs using view\n",
    "        x = x.view(x.size()[0]*x.size()[1], self.n_hidden)\n",
    "        \n",
    "        ## Put x through the fully-connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Return x and the hidden state (h, c)\n",
    "        return x, (h, c)\n",
    "    \n",
    "    \n",
    "    def predict(self, char, h=None, cuda=False, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "        \n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        if cuda:\n",
    "            self.cuda()\n",
    "        else:\n",
    "            self.cpu()\n",
    "        \n",
    "        if h is None:\n",
    "            h = self.init_hidden(1)\n",
    "        \n",
    "        x = np.array([[self.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(self.chars))\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        out, h = self.forward(inputs, h)\n",
    "\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        \n",
    "        if cuda:\n",
    "            p = p.cpu()\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(self.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        \n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "            \n",
    "        return self.int2char[char], h\n",
    "    \n",
    "    def init_weights(self):\n",
    "        ''' Initialize weights for fully connected layer '''\n",
    "        initrange = 0.1\n",
    "        \n",
    "        # Set bias tensor to all zeros\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        # FC weights as random uniform\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_(),\n",
    "                weight.new(self.n_layers, n_seqs, self.n_hidden).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Encoding by FastAI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def uniqueify(x, sort=False):\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if sort: res.sort()\n",
    "    return res\n",
    "\n",
    "class Processor():\n",
    "    def process(self, items): return items\n",
    "\n",
    "class CategoryProcessor(Processor):\n",
    "    def __init__(self,default_token=None): \n",
    "        self.vocab=None\n",
    "        self.default_token=default_token\n",
    "\n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            self.vocab = uniqueify(items)\n",
    "            if self.default_token is not None:\n",
    "                for o in reversed(self.default_token):\n",
    "                    if o in self.vocab: self.vocab.remove(o)\n",
    "                    self.vocab.insert(0, o)\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return self.otoi[item]\n",
    "\n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    def deproc1(self, idx): return self.vocab[idx]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "user_numericalize=CategoryProcessor(default_spec_tok)\n",
    "user_numericalize(df['org:resource'])\n",
    "\n",
    "activity_numericalize=CategoryProcessor(default_spec_tok)\n",
    "activity_numericalize(df['concept:name']);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "%%time\n",
    "\n",
    "def create_traces(df):\n",
    "    ll=[]\n",
    "    trace_ids=[]\n",
    "    \n",
    "    for n, g in df.groupby('trace_id'):\n",
    "        ea = activity_numericalize(g['concept:name'])\n",
    "        eu = user_numericalize(g['org:resource'])\n",
    "        ll.append([ea, eu])\n",
    "        trace_ids.append(n)\n",
    "\n",
    "    df2 = pd.DataFrame(ll, columns=[\"Activities\",'Users'])\n",
    "    df2.index = trace_ids\n",
    "    return df2\n",
    "\n",
    "data = create_traces(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpm2",
   "language": "python",
   "name": "fastpm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
