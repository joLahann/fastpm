{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Flow Prediction -> Part 2: Suffix Training\n",
    "===\n",
    "\n",
    "\n",
    "Process Prediction that focuses only on the control flow perspective of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from exp.control_flow_prediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=import_xes(untar_data(URLs.BPIC_2012)).events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: LabeledData\n",
       "x: ControlFlowList (10667 items)\n",
       "['9->10->12->4->4->16->13->17->14->15->5->4->5->5->5->5->5->19->7->5->7->21->22->24->23->7->3', '9->10->12->4->4->4->4->16->17->13->14->15->5->4->5->5->5->13->18->14->15->5->5->5->5->5->19->7->5->7->7->7->7->7->24->22->21->23->7->3'...]\n",
       "y: ControlFlowList (10667 items)\n",
       "['0', '0'...]\n",
       "\n",
       "Valid: LabeledData\n",
       "x: ControlFlowList (1303 items)\n",
       "['9->10->12->4->4->4->4->16->17->13->14->15->5->4->5->19->7->5->7->24->21->23->22->7->3', '9->10->11->3'...]\n",
       "y: ControlFlowList (1303 items)\n",
       "['0', '0'...]\n",
       "\n",
       "Test: LabeledData\n",
       "x: ControlFlowList (1117 items)\n",
       "['9->10->12->4->4->4->4->4->4->4->4->16->17->13->14->15->5->4->5->13->18->14->15->5->5->5->5->5->5->5->5->5->13->18->14->15->5->5->5->5->5->5->5->5->5->5->5->5->5->19->7->5->7->24->22->21->23->7->27->3', '9->10->12->4->4->4->4->4->4->4->4->16->13->17->14->15->5->4->5->5->5->5->5->5->5->5->5->5->5->5->5->5->5->19->7->5->7->6->7->6->6->6->6->6->6->6->7->6->7->6->7->6->6->6->7->6->7->6->7->6->6->6->6->6->7->6->7->7->7->7->7->24->23->21->22->7->3'...]\n",
       "y: ControlFlowList (1117 items)\n",
       "['0', '0'...]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfl=ControlFlowList.from_df(log)\n",
    "sd=SplitData.split_by_func(cfl, partial(random_splitter, p_valid=0.1))\n",
    "proc_tok,proc_num = TokenizeProcessor(),NumericalizeProcessor()\n",
    "ll = label_by_func(sd, lambda x: 0, proc_x = [proc_tok,proc_num])\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _prepare_suffix_prediction(ds, test=False):\n",
    "    x,y=[],[]\n",
    "    \n",
    "    for o in ds.x.items:\n",
    "        if len(o)<=1: continue\n",
    "        x.append(tensor(o[:len(o)//2]))\n",
    "        y.append(tensor(o[len(o)//2:]))\n",
    "    return x,y\n",
    "\n",
    "def suffix_data_set(data):\n",
    "    return Dataset(*_prepare_suffix_prediction(data))    \n",
    "\n",
    "def get_suffix_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_ds,valid_ds=suffix_data_set(train_ds),suffix_data_set(valid_ds)\n",
    "    train_sampler = SortishSampler(train_ds.x, key=lambda t: len(train_ds[t][0]), bs=bs//2)\n",
    "    valid_sampler = SortSampler(valid_ds.x, key=lambda t: len(valid_ds[t][0]))\n",
    "    return (DataLoader(train_ds, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate_sp,drop_last=True),\n",
    "           DataLoader(valid_ds, batch_size=bs, sampler=valid_sampler, collate_fn=pad_collate_sp,drop_last=True))\n",
    "\n",
    "def suffix_databunchify(ll, bs, **kwargs):\n",
    "    return DataBunch(*get_suffix_dls(ll.train, ll.valid, bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=suffix_databunchify(ll,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(data.train_dl)\n",
    "xb,yb = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 85])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 86])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = partial(seq2seq_collate, pad_idx=1, pad_first=False, backwards=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(DeviceDataLoader(data.train_dl,device=None,collate_fn=collate_fn))\n",
    "xb,yb = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, c=None):\n",
    "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
    "\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=DataBunch(DeviceDataLoader(data.train_dl,device=None,collate_fn=collate_fn),DeviceDataLoader(data.train_dl,device=None,collate_fn=collate_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models.qrnn import QRNN, QRNNLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(itos, em_sz=12, mult=1.):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = create_emb(proc_num.vocab)\n",
    "emb_dec = create_emb(proc_num.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_param(m: nn.Module): \n",
    "    \"Return the first parameter of `m`.\"\n",
    "    return next(m.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqQRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, n_hid, max_len, n_layers=2, p_inp:float=0.15, p_enc:float=0.25, \n",
    "                 p_dec:float=0.1, p_out:float=0.35, p_hid:float=0.05, bos_idx:int=0, pad_idx:int=1):\n",
    "        super().__init__()\n",
    "        self.n_layers,self.n_hid,self.max_len,self.bos_idx,self.pad_idx = n_layers,n_hid,max_len,bos_idx,pad_idx\n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(p_inp)\n",
    "        self.encoder = QRNN(emb_enc.weight.size(1), n_hid, n_layers=n_layers, dropout=p_enc)\n",
    "        self.out_enc = nn.Linear(n_hid, emb_enc.weight.size(1), bias=False)\n",
    "        self.hid_dp  = nn.Dropout(p_hid)\n",
    "        self.emb_dec = emb_dec\n",
    "        self.decoder = QRNN(emb_dec.weight.size(1), emb_dec.weight.size(1), n_layers=n_layers, dropout=p_dec)\n",
    "        self.out_drop = nn.Dropout(p_out)\n",
    "        self.out = nn.Linear(emb_dec.weight.size(1), emb_dec.weight.size(0))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        bs,sl = inp.size()\n",
    "        self.encoder.reset()\n",
    "        self.decoder.reset()\n",
    "        hid = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.encoder(emb, hid)\n",
    "        hid = self.out_enc(self.hid_dp(hid))\n",
    "\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        outs = []\n",
    "        for i in range(self.max_len):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "            out, hid = self.decoder(emb, hid)\n",
    "            out = self.out(self.out_drop(out[:,0]))\n",
    "            outs.append(out)\n",
    "            dec_inp = out.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "        return torch.stack(outs, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(self.n_layers, bs, self.n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return cross_entropy_flat(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqQRNN(\n",
       "  (emb_enc): Embedding(28, 12, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
       "  (encoder): QRNN(\n",
       "    (layers): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): Linear(in_features=24, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): Linear(in_features=256, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_enc): Linear(in_features=256, out_features=12, bias=False)\n",
       "  (hid_dp): Dropout(p=0.05, inplace=False)\n",
       "  (emb_dec): Embedding(28, 12, padding_idx=1)\n",
       "  (decoder): QRNN(\n",
       "    (layers): ModuleList(\n",
       "      (0): QRNNLayer(\n",
       "        (linear): Linear(in_features=24, out_features=36, bias=True)\n",
       "      )\n",
       "      (1): QRNNLayer(\n",
       "        (linear): Linear(in_features=12, out_features=36, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_drop): Dropout(p=0.35, inplace=False)\n",
       "  (out): Linear(in_features=12, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2SeqQRNN(emb_enc, emb_dec, 256, 30, n_layers=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0526, -0.1494, -0.2041,  ...,  0.1205, -0.0501,  0.1233],\n",
       "         [-0.1465, -0.1494, -0.0569,  ...,  0.0207, -0.0877,  0.1662],\n",
       "         [-0.2013, -0.1494, -0.4419,  ...,  0.3452,  0.0112,  0.3932],\n",
       "         ...,\n",
       "         [-0.4411, -0.1494, -0.3355,  ...,  0.7847, -0.4683,  0.5193],\n",
       "         [-0.6012, -0.1494, -0.0510,  ...,  0.5593, -0.1546,  1.1052],\n",
       "         [-0.7021, -0.1494, -0.0491,  ...,  1.0444, -0.3544,  1.1511]],\n",
       "\n",
       "        [[-0.0375, -0.1494, -0.0203,  ...,  0.0669, -0.3033,  0.1301],\n",
       "         [-0.1031, -0.1494, -0.0083,  ...,  0.1297, -0.2545,  0.3791],\n",
       "         [-0.0907, -0.1494, -0.4780,  ...,  0.2028, -0.1492,  0.1026],\n",
       "         ...,\n",
       "         [-0.0867, -0.1494, -0.4119,  ...,  0.4178,  0.4033,  0.2268],\n",
       "         [-0.5491, -0.1494,  0.1563,  ...,  0.4440, -0.3595,  1.1090],\n",
       "         [-0.4677, -0.1494, -0.0649,  ...,  0.6259,  0.3134,  0.6318]],\n",
       "\n",
       "        [[-0.2093, -0.1494, -0.3323,  ..., -0.0428, -0.0350,  0.0720],\n",
       "         [-0.0625, -0.1494, -0.2847,  ..., -0.0683,  0.0183,  0.1325],\n",
       "         [-0.0626, -0.1494, -0.2114,  ..., -0.1171,  0.0324,  0.2303],\n",
       "         ...,\n",
       "         [-0.3857, -0.1494,  0.0787,  ...,  0.2274, -0.0572,  0.8636],\n",
       "         [-0.1956, -0.1494, -0.3136,  ...,  0.3759, -0.0722,  0.6096],\n",
       "         [-0.0973, -0.1494, -0.2836,  ...,  0.5929, -0.1475,  0.6317]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1647, -0.1494, -0.2689,  ..., -0.0012, -0.0580,  0.1012],\n",
       "         [-0.2151, -0.1494, -0.0792,  ...,  0.1687, -0.3990,  0.3958],\n",
       "         [-0.1547, -0.1494, -0.1912,  ..., -0.1681,  0.0257,  0.0805],\n",
       "         ...,\n",
       "         [ 0.0853, -0.1494, -0.4274,  ...,  0.3021,  0.0352,  0.1717],\n",
       "         [-0.0606, -0.1494, -0.3282,  ...,  0.3111, -0.2572,  0.4492],\n",
       "         [-0.4127, -0.1494,  0.3343,  ...,  0.2408, -0.4064,  0.8832]],\n",
       "\n",
       "        [[-0.1668, -0.1494, -0.2904,  ..., -0.1000, -0.1349,  0.1324],\n",
       "         [-0.2942, -0.1494, -0.3610,  ...,  0.2229,  0.0338,  0.2903],\n",
       "         [-0.3822, -0.1494,  0.0104,  ...,  0.3917, -0.4592,  0.7715],\n",
       "         ...,\n",
       "         [-0.6104, -0.1494, -0.2954,  ..., -0.0441,  0.0213,  0.3665],\n",
       "         [-0.5219, -0.1494, -0.1576,  ..., -0.3781, -0.1015,  0.4017],\n",
       "         [-0.4028, -0.1494, -0.3274,  ...,  0.3079, -0.1364,  0.5270]],\n",
       "\n",
       "        [[-0.0958, -0.1494, -0.0861,  ...,  0.1956, -0.2427,  0.1976],\n",
       "         [-0.2548, -0.1494,  0.0089,  ...,  0.3058, -0.2898,  0.3044],\n",
       "         [-0.1115, -0.1494,  0.1030,  ...,  0.4661, -0.1890,  0.6154],\n",
       "         ...,\n",
       "         [ 0.0023, -0.1494, -0.2979,  ...,  0.0152,  0.3869,  0.3339],\n",
       "         [-0.1349, -0.1494, -0.1998,  ...,  0.5446,  0.0195,  0.4461],\n",
       "         [-0.3220, -0.1494, -0.0292,  ...,  0.6150,  0.0320,  0.9120]]],\n",
       "       device='cuda:0', grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.path='./'\n",
    "data.device=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model.cuda(), loss_func=seq2seq_loss, metrics=[seq2seq_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.empty_val=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      68.00% [17/25 05:43<02:41]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.612582</td>\n",
       "      <td>0.570931</td>\n",
       "      <td>0.813059</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686607</td>\n",
       "      <td>0.615983</td>\n",
       "      <td>0.796668</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>0.633115</td>\n",
       "      <td>0.792349</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.761071</td>\n",
       "      <td>0.620560</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.750448</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.788232</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.716639</td>\n",
       "      <td>0.679755</td>\n",
       "      <td>0.789590</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.803896</td>\n",
       "      <td>0.824094</td>\n",
       "      <td>0.733160</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.871752</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>0.744414</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.954145</td>\n",
       "      <td>0.721140</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.857448</td>\n",
       "      <td>0.766350</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.836502</td>\n",
       "      <td>0.715685</td>\n",
       "      <td>0.772413</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.733123</td>\n",
       "      <td>0.756160</td>\n",
       "      <td>0.749287</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.731090</td>\n",
       "      <td>0.760341</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.825689</td>\n",
       "      <td>0.676971</td>\n",
       "      <td>0.785737</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.770244</td>\n",
       "      <td>0.660792</td>\n",
       "      <td>0.792384</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.815768</td>\n",
       "      <td>0.690854</td>\n",
       "      <td>0.786175</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.670038</td>\n",
       "      <td>0.776993</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='333', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7bb77bc20618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_validate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 val_loss = validate(learn.model, learn.data.valid_dl, loss_func=learn.loss_func,\n\u001b[0;32m--> 106\u001b[0;31m                                        cb_handler=cb_handler, pbar=pbar)\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b9067a00811e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hid)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mnew_hid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/fastai/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hid)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_gate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_gate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_gate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                \u001b[0mz_gate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_gate\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastpm2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(25, 4e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.data.valid_dl):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(x)\n",
    "                targets.append(y)\n",
    "                outputs.append(z.argmax(1))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='333' class='' max='333', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [333/333 00:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A_SUBMITTED * A_PARTLYSUBMITTED * A_PREACCEPTED * W_Completeren aanvraag * W_Completeren aanvraag * A_ACCEPTED * A_FINALIZED * O_SELECTED * O_CREATED * O_SENT * W_Nabellen offertes * W_Completeren aanvraag * W_Nabellen offertes * O_SELECTED * O_CANCELLED * O_CREATED * O_SENT * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * O_SELECTED * O_CANCELLED * O_CREATED * O_SENT * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * O_SELECTED * O_CANCELLED * O_CREATED * O_SENT * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([inputs[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W_Nabellen offertes * O_SENT_BACK * W_Valideren aanvraag * W_Nabellen offertes * W_Valideren aanvraag * W_Valideren aanvraag * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Valideren aanvraag * O_ACCEPTED * A_APPROVED * A_REGISTERED * A_ACTIVATED * W_Valideren aanvraag * xxeot * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad * xxpad'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([targets[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen offertes * W_Nabellen incomplete dossiers * W_Nabellen offertes * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Valideren aanvraag'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([outputs[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(t_dl)\n",
    "xb,yb = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    \n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.pr_force = 1 - 0.5 * epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqQRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, n_hid, max_len, n_layers=2, p_inp:float=0.15, p_enc:float=0.25, \n",
    "                 p_dec:float=0.1, p_out:float=0.35, p_hid:float=0.05, bos_idx:int=0, pad_idx:int=1):\n",
    "        super().__init__()\n",
    "        self.n_layers,self.n_hid,self.max_len,self.bos_idx,self.pad_idx = n_layers,n_hid,max_len,bos_idx,pad_idx\n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(p_inp)\n",
    "        self.encoder = QRNN(emb_enc.weight.size(1), n_hid, n_layers=n_layers, dropout=p_enc)\n",
    "        self.out_enc = nn.Linear(n_hid, emb_enc.weight.size(1), bias=False)\n",
    "        self.hid_dp  = nn.Dropout(p_hid)\n",
    "        self.emb_dec = emb_dec\n",
    "        self.decoder = QRNN(emb_dec.weight.size(1), emb_dec.weight.size(1), n_layers=n_layers, dropout=p_dec)\n",
    "        self.out_drop = nn.Dropout(p_out)\n",
    "        self.out = nn.Linear(emb_dec.weight.size(1), emb_dec.weight.size(0))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 0.\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs,sl = inp.size()\n",
    "        hid = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.encoder(emb, hid)\n",
    "        hid = self.out_enc(self.hid_dp(hid))\n",
    "\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        res = []\n",
    "        for i in range(self.max_len):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "            outp, hid = self.decoder(emb, hid)\n",
    "            outp = self.out(self.out_drop(outp[:,0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: break\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(self.n_layers, bs, self.n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = create_emb(proc_num.vocab,em_sz=16)\n",
    "emb_dec = create_emb(proc_num.vocab,em_sz=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqQRNN(emb_enc, emb_dec, 256, 30, n_layers=2)\n",
    "learn = Learner(data, model.cuda(), loss_func=seq2seq_loss, metrics=[seq2seq_acc],\n",
    "                callback_fns=partial(TeacherForcing, end_epoch=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.387480</td>\n",
       "      <td>2.885957</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.891848</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>0.561487</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593510</td>\n",
       "      <td>2.117422</td>\n",
       "      <td>0.643699</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.492097</td>\n",
       "      <td>1.937095</td>\n",
       "      <td>0.637832</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.511218</td>\n",
       "      <td>2.131192</td>\n",
       "      <td>0.602447</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.552228</td>\n",
       "      <td>1.317405</td>\n",
       "      <td>0.688032</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.522177</td>\n",
       "      <td>1.279400</td>\n",
       "      <td>0.673095</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.607179</td>\n",
       "      <td>1.029300</td>\n",
       "      <td>0.679754</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.543112</td>\n",
       "      <td>1.040118</td>\n",
       "      <td>0.685587</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.672243</td>\n",
       "      <td>0.780057</td>\n",
       "      <td>0.752226</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.590708</td>\n",
       "      <td>0.757405</td>\n",
       "      <td>0.752920</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.552432</td>\n",
       "      <td>0.694766</td>\n",
       "      <td>0.783404</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.540699</td>\n",
       "      <td>0.691349</td>\n",
       "      <td>0.790142</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.596464</td>\n",
       "      <td>0.655955</td>\n",
       "      <td>0.796445</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.723970</td>\n",
       "      <td>0.632713</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.671281</td>\n",
       "      <td>0.593174</td>\n",
       "      <td>0.811685</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.564955</td>\n",
       "      <td>0.597178</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.625014</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>0.809552</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.654159</td>\n",
       "      <td>0.582629</td>\n",
       "      <td>0.812562</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.590689</td>\n",
       "      <td>0.591053</td>\n",
       "      <td>0.810257</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A_SUBMITTED * A_PARTLYSUBMITTED * A_PREACCEPTED * W_Completeren aanvraag * W_Completeren aanvraag * W_Completeren aanvraag * W_Completeren aanvraag * A_ACCEPTED * O_SELECTED * A_FINALIZED * O_CREATED * O_SENT * W_Nabellen offertes * W_Completeren aanvraag * W_Nabellen offertes * O_SENT_BACK * W_Valideren aanvraag * W_Nabellen offertes * W_Valideren aanvraag * W_Valideren aanvraag * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * xxpad * xxpad'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([inputs[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * O_CANCELLED * A_CANCELLED * W_Nabellen incomplete dossiers * xxeot * xxpad * xxpad'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([targets[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Nabellen incomplete dossiers * W_Valideren aanvraag * W_Valideren aanvraag * W_Valideren aanvraag * W_Valideren aanvraag * xxeot'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" * \".join(proc_num.deprocess([outputs[i].cpu().tolist()])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(t_dl)\n",
    "xb,yb = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"*\".join(proc_num.deprocess(inputs[3:4])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[3].cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "       partial(AvgStatsCallback,seq2seq_acc),\n",
    "       CudaCallback,\n",
    "        Recorder,\n",
    "    \n",
    "        partial(ParamScheduler, 'lr', sched),\n",
    "     #  partial(GradientClipping, clip=0.1),\n",
    "       ProgressBarCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=suffix_databunchify(ll,2*1048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = create_emb(proc_num.vocab,em_sz=16)\n",
    "emb_dec = create_emb(proc_num.vocab,em_sz=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CudaCallback??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqQRNN(emb_enc, emb_dec, 64, 174, n_layers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, data, seq2seq_loss, lr=1e-3, cb_funcs=cbs, opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(Callback):\n",
    "    \n",
    "    def __init__(self, end_epoch):\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.model.pr_force = 1 - 0.5 * epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqQRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, n_hid, max_len, n_layers=2, p_inp:float=0.15, p_enc:float=0.25, \n",
    "                 p_dec:float=0.1, p_out:float=0.35, p_hid:float=0.05, bos_idx:int=0, pad_idx:int=1):\n",
    "        super().__init__()\n",
    "        self.n_layers,self.n_hid,self.max_len,self.bos_idx,self.pad_idx = n_layers,n_hid,max_len,bos_idx,pad_idx\n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(p_inp)\n",
    "        self.encoder = QRNN(emb_enc.weight.size(1), n_hid, n_layers=n_layers, dropout=p_enc)\n",
    "        self.out_enc = nn.Linear(n_hid, emb_enc.weight.size(1), bias=False)\n",
    "        self.hid_dp  = nn.Dropout(p_hid)\n",
    "        self.emb_dec = emb_dec\n",
    "        self.decoder = QRNN(emb_dec.weight.size(1), emb_dec.weight.size(1), n_layers=n_layers, dropout=p_dec)\n",
    "        self.out_drop = nn.Dropout(p_out)\n",
    "        self.out = nn.Linear(emb_dec.weight.size(1), emb_dec.weight.size(0))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 0.\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs,sl = inp.size()\n",
    "        hid = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.encoder(emb, hid)\n",
    "        hid = self.out_enc(self.hid_dp(hid))\n",
    "\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        res = []\n",
    "        for i in range(self.max_len):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "            outp, hid = self.decoder(emb, hid)\n",
    "            outp = self.out(self.out_drop(outp[:,0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: break\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(self.n_layers, bs, self.n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "       partial(AvgStatsCallback,seq2seq_acc),\n",
    "       CudaCallback,\n",
    "        Recorder,\n",
    "        partial(TeacherForcing, end_epoch=8),\n",
    "        partial(ParamScheduler, 'lr', sched),\n",
    "     #  partial(GradientClipping, clip=0.1),\n",
    "       ProgressBarCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = create_emb(proc_num.vocab,em_sz=16)\n",
    "emb_dec = create_emb(proc_num.vocab,em_sz=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqQRNN(emb_enc, emb_dec, 256, 100, n_layers=2)\n",
    "learn = Learner(model, data, seq2seq_loss, lr=1e-5, cb_funcs=cbs, opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, itos, em_sz_enc, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.emb_enc = nn.Embedding(len(itos), em_sz_enc, padding_idx=1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "                        \n",
    "        self.emb_dec = nn.Embedding(len(itos), em_sz_dec, padding_idx=1)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "    def forward(self, inp):\n",
    "        bs,sl = inp.size()\n",
    "        h = self.initHidden(inp,bs)\n",
    "       \n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp.T))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = Variable(inp.new_zeros(bs))\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = Variable(outp.data.max(1)[1].float()).long()\n",
    "            if (dec_inp==1).all(): break\n",
    "        res=torch.stack(res)\n",
    "        return res\n",
    "    \n",
    "    def initHidden(self,t, bs): \n",
    "        #return Variable(torch.zeros(self.nl, bs, self.nh))\n",
    "        return Variable(t.new_zeros((self.nl, bs, self.nh)).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    bs,sl = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.reshape(-1,nc), target.T.reshape(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Seq2SeqRNN(proc_num.vocab,10,10,8,174)\n",
    "pred=model(xb);pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_loss(pred,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "       #partial(AvgStatsCallback,accuracy_flat),\n",
    "       CudaCallback, Recorder,\n",
    "       partial(GradientClipping, clip=0.1),\n",
    "       ProgressBarCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=suffix_databunchify(ll,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(Seq2SeqRNN(proc_num.vocab,10,10,8,174), data, seq2seq_loss, lr=5e-3, cb_funcs=cbs, opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpm2",
   "language": "python",
   "name": "fastpm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
