{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialized LSTM (Camargo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/AdaptiveBProcess/GenerativeLSTM/tree/a1c36d27691be5d38652512b086e8f9b6d60229d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Feb 28 10:15:12 2019\n",
    "@author: Manuel Camargo\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Nadam, Adam, SGD, Adagrad\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def training_model(vec, ac_weights, rl_weights, output_folder, args):\n",
    "    \"\"\"Example function with types documented in the docstring.\n",
    "    Args:\n",
    "        param1 (int): The first parameter.\n",
    "        param2 (str): The second parameter.\n",
    "    Returns:\n",
    "        bool: The return value. True for success, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Build model...')\n",
    "    print(args)\n",
    "# =============================================================================\n",
    "#     Input layer\n",
    "# =============================================================================\n",
    "    ac_input = Input(shape=(vec['prefixes']['x_ac_inp'].shape[1], ), name='ac_input')\n",
    "    rl_input = Input(shape=(vec['prefixes']['x_rl_inp'].shape[1], ), name='rl_input')\n",
    "    t_input = Input(shape=(vec['prefixes']['xt_inp'].shape[1], 1), name='t_input')\n",
    "\n",
    "# =============================================================================\n",
    "#    Embedding layer for categorical attributes        \n",
    "# =============================================================================\n",
    "    ac_embedding = Embedding(ac_weights.shape[0],\n",
    "                            ac_weights.shape[1],\n",
    "                            weights=[ac_weights],\n",
    "                            input_length=vec['prefixes']['x_ac_inp'].shape[1],\n",
    "                            trainable=False, name='ac_embedding')(ac_input)\n",
    "\n",
    "    rl_embedding = Embedding(rl_weights.shape[0],\n",
    "                            rl_weights.shape[1],\n",
    "                            weights=[rl_weights],\n",
    "                            input_length=vec['prefixes']['x_rl_inp'].shape[1],\n",
    "                            trainable=False, name='rl_embedding')(rl_input)\n",
    "# =============================================================================\n",
    "#    Layer 1\n",
    "# =============================================================================\n",
    "    l1_c1 = LSTM(args['l_size'],\n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  return_sequences=True,\n",
    "                  dropout=0.2,\n",
    "                  implementation=args['imp'])(ac_embedding)\n",
    "    \n",
    "    l1_c2 = LSTM(args['l_size'],\n",
    "                  kernel_initializer='glorot_uniform',\n",
    "                  return_sequences=True,\n",
    "                  dropout=0.2,\n",
    "                  implementation=args['imp'])(rl_embedding)\n",
    "\n",
    "    if args['lstm_act'] is not None:\n",
    "        l1_c3 = LSTM(args['l_size'],\n",
    "                     activation=args['lstm_act'],\n",
    "                     kernel_initializer='glorot_uniform',\n",
    "                     return_sequences=True,\n",
    "                     dropout=0.2,\n",
    "                     implementation=args['imp'])(t_input)\n",
    "    else:\n",
    "        l1_c3 = LSTM(args['l_size'],\n",
    "                     kernel_initializer='glorot_uniform',\n",
    "                     return_sequences=True,\n",
    "                     dropout=0.2,\n",
    "                     implementation=args['imp'])(t_input)\n",
    "\n",
    "# =============================================================================\n",
    "#    Batch Normalization Layer\n",
    "# =============================================================================\n",
    "    batch1 = BatchNormalization()(l1_c1)\n",
    "    batch2 = BatchNormalization()(l1_c2)\n",
    "    batch3 = BatchNormalization()(l1_c3)\n",
    "    \n",
    "# =============================================================================\n",
    "# The layer specialized in prediction\n",
    "# =============================================================================\n",
    "    l2_c1 = LSTM(args['l_size'],\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    return_sequences=False,\n",
    "                    dropout=0.2,\n",
    "                    implementation=args['imp'])(batch1)\n",
    " \n",
    "#   The layer specialized in role prediction\n",
    "    l2_c2 = LSTM(args['l_size'],\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    return_sequences=False,\n",
    "                    dropout=0.2,\n",
    "                    implementation=args['imp'])(batch2)\n",
    "    \n",
    "#   The layer specialized in role prediction\n",
    "    if args['lstm_act'] is not None:\n",
    "        l2_3 = LSTM(args['l_size'],\n",
    "                    activation=args['lstm_act'],\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    return_sequences=False,\n",
    "                    dropout=0.2,\n",
    "                    implementation=args['imp'])(batch3)\n",
    "    else:\n",
    "        l2_3 = LSTM(args['l_size'],\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    return_sequences=False,\n",
    "                    dropout=0.2,\n",
    "                    implementation=args['imp'])(batch3)\n",
    "    \n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "# Output Layer\n",
    "# =============================================================================\n",
    "    act_output = Dense(ac_weights.shape[0],\n",
    "                       activation='softmax',\n",
    "                       kernel_initializer='glorot_uniform',\n",
    "                       name='act_output')(l2_c1)\n",
    "\n",
    "    role_output = Dense(rl_weights.shape[0],\n",
    "                       activation='softmax',\n",
    "                       kernel_initializer='glorot_uniform',\n",
    "                       name='role_output')(l2_c2)\n",
    "\n",
    "    if args['dense_act'] is not None:\n",
    "        time_output = Dense(1, activation=args['dense_act'],\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            name='time_output')(l2_3)\n",
    "    else:\n",
    "        time_output = Dense(1,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            name='time_output')(l2_3)\n",
    "\n",
    "    model = Model(inputs=[ac_input, rl_input, t_input], outputs=[act_output, role_output, time_output])\n",
    "\n",
    "    if args['optim'] == 'Nadam':\n",
    "        opt = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999,\n",
    "                    epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n",
    "    elif args['optim'] == 'Adam':\n",
    "        opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                   epsilon=None, decay=0.0, amsgrad=False)\n",
    "    elif args['optim'] == 'SGD':\n",
    "        opt = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    elif args['optim'] == 'Adagrad':\n",
    "        opt = Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "\n",
    "    model.compile(loss={'act_output':'categorical_crossentropy', 'role_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "\n",
    "    # Output file\n",
    "    output_file_path = os.path.join(output_folder,\n",
    "                                    'model_rd_' + str(args['l_size']) +\n",
    "                                    ' ' + args['optim'] +\n",
    "                                    '_{epoch:02d}-{val_loss:.2f}.h5')\n",
    "\n",
    "    # Saving\n",
    "    model_checkpoint = ModelCheckpoint(output_file_path,\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=0,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='auto')\n",
    "    lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.5,\n",
    "                                   patience=10,\n",
    "                                   verbose=0,\n",
    "                                   mode='auto',\n",
    "                                   min_delta=0.0001,\n",
    "                                   cooldown=0,\n",
    "                                   min_lr=0)\n",
    "\n",
    "    model.fit({'ac_input':vec['prefixes']['x_ac_inp'],\n",
    "               'rl_input':vec['prefixes']['x_rl_inp'],\n",
    "               't_input':vec['prefixes']['xt_inp']},\n",
    "              {'act_output':vec['next_evt']['y_ac_inp'],\n",
    "               'role_output':vec['next_evt']['y_rl_inp'],\n",
    "               'time_output':vec['next_evt']['yt_inp']},\n",
    "              validation_split=0.2,\n",
    "              verbose=2,\n",
    "              callbacks=[early_stopping, model_checkpoint, lr_reducer],\n",
    "              batch_size=vec['prefixes']['x_ac_inp'].shape[1],\n",
    "              epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Mar 17 20:35:53 2020\n",
    "@author: Manuel Camargo\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "#from support_modules import support as sup\n",
    "\n",
    "\n",
    "class NextEventPredictor():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"constructor\"\"\"\n",
    "        self.model = None\n",
    "        self.examples = dict()\n",
    "        self.imp = 'Arg Max'\n",
    "\n",
    "    def predict(self, params, model, examples, imp):\n",
    "        self.model = model\n",
    "        self.examples = examples\n",
    "        self.imp = imp\n",
    "        predictor = self._get_predictor(params['model_type'])\n",
    "        #sup.print_performed_task('Predicting next events')\n",
    "        return predictor(params)\n",
    "\n",
    "    def _get_predictor(self, model_type):\n",
    "        if model_type == 'shared_cat':\n",
    "            return self._predict_next_event_shared_cat\n",
    "        else:\n",
    "            raise ValueError(model_type)\n",
    "\n",
    "    def _predict_next_event_shared_cat(self, parameters):\n",
    "        \"\"\"Generate business process suffixes using a keras trained model.\n",
    "        Args:\n",
    "            model (keras model): keras trained model.\n",
    "            prefixes (list): list of prefixes.\n",
    "            ac_index (dict): index of activities.\n",
    "            rl_index (dict): index of roles.\n",
    "            imp (str): method of next event selection.\n",
    "        \"\"\"\n",
    "        # Generation of predictions\n",
    "        results = list()\n",
    "        for i, _ in enumerate(self.examples['prefixes']['activities']):\n",
    "            # Activities and roles input shape(1,5)\n",
    "            x_ac_ngram = np.append(\n",
    "                    np.zeros(parameters['dim']['time_dim']),\n",
    "                    np.array(self.examples['prefixes']['activities'][i]), axis=0)[-parameters['dim']['time_dim']:].reshape((1, parameters['dim']['time_dim']))\n",
    "\n",
    "            x_rl_ngram = np.append(\n",
    "                    np.zeros(parameters['dim']['time_dim']),\n",
    "                    np.array(self.examples['prefixes']['roles'][i]),\n",
    "                    axis=0)[-parameters['dim']['time_dim']:].reshape((1, parameters['dim']['time_dim']))\n",
    "\n",
    "            # times input shape(1,5,1)\n",
    "            x_t_ngram = np.array([np.append(\n",
    "                    np.zeros(parameters['dim']['time_dim']),\n",
    "                    np.array(self.examples['prefixes']['times'][i]),\n",
    "                    axis=0)[-parameters['dim']['time_dim']:].reshape((parameters['dim']['time_dim'], 1))])\n",
    "            # add intercase features if necessary\n",
    "            if parameters['model_type'] == 'shared_cat':\n",
    "                inputs = [x_ac_ngram, x_rl_ngram, x_t_ngram]\n",
    "            elif parameters['model_type'] == 'shared_cat_inter':\n",
    "                # times input shape(1,5,1)\n",
    "                inter_attr_num = self.examples['prefixes']['inter_attr'][i].shape[1]\n",
    "                x_inter_ngram = np.array([np.append(\n",
    "                        np.zeros((parameters['dim']['time_dim'], inter_attr_num)),\n",
    "                        self.examples['prefixes']['inter_attr'][i],\n",
    "                        axis=0)[-parameters['dim']['time_dim']:].reshape((parameters['dim']['time_dim'], inter_attr_num))])\n",
    "                inputs = [x_ac_ngram, x_rl_ngram, x_t_ngram, x_inter_ngram]\n",
    "            # predict\n",
    "            predictions = self.model.predict(inputs)\n",
    "            if self.imp == 'Random Choice':\n",
    "                # Use this to get a random choice following as PDF\n",
    "                pos = np.random.choice(np.arange(0, len(predictions[0][0])),\n",
    "                                       p=predictions[0][0])\n",
    "                pos1 = np.random.choice(np.arange(0, len(predictions[1][0])),\n",
    "                                        p=predictions[1][0])\n",
    "            elif self.imp == 'Arg Max':\n",
    "                # Use this to get the max prediction\n",
    "                pos = np.argmax(predictions[0][0])\n",
    "                pos1 = np.argmax(predictions[1][0])\n",
    "            # save results\n",
    "            results.append({\n",
    "                'ac_prefix': self.examples['prefixes']['activities'][i],\n",
    "                'ac_expect': self.examples['next_evt']['activities'][i],\n",
    "                'ac_pred': pos,\n",
    "                'rl_prefix': self.examples['prefixes']['roles'][i],\n",
    "                'rl_expect': self.examples['next_evt']['roles'][i],\n",
    "                'rl_pred': pos1})\n",
    "        #sup.print_done_task()\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpm2",
   "language": "python",
   "name": "fastpm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
