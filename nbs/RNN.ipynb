{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.eventlog import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to parse date: 1970-01-01T00:00:00.000+01:00\n",
      "failed to parse date: 1970-01-01T00:00:00.000+01:00\n",
      "failed to parse date: 2012-04-23T00:00:00.000+02:00\n",
      "failed to parse date: 2011-10-01T00:38:44.546+02:00\n",
      "failed to parse date: 2012-03-14T16:04:54.681+01:00\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.BPIC_2012)\n",
    "log = import_xes(path,extensions=False,classifiers=False,schema=False,log_attributes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173688</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.546000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173688</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-09-30 22:38:44.880000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173688</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-09-30 22:39:37.906000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173688</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 09:36:46.437000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trace_id  event_id org:resource lifecycle:transition  \\\n",
       "0   173688         0          112             COMPLETE   \n",
       "1   173688         1          112             COMPLETE   \n",
       "2   173688         2          112             COMPLETE   \n",
       "3   173688         3          112             SCHEDULE   \n",
       "4   173688         4         None                START   \n",
       "\n",
       "             concept:name                   time:timestamp  \n",
       "0             A_SUBMITTED 2011-09-30 22:38:44.546000+00:00  \n",
       "1       A_PARTLYSUBMITTED 2011-09-30 22:38:44.880000+00:00  \n",
       "2           A_PREACCEPTED 2011-09-30 22:39:37.906000+00:00  \n",
       "3  W_Completeren aanvraag 2011-09-30 22:39:38.875000+00:00  \n",
       "4  W_Completeren aanvraag 2011-10-01 09:36:46.437000+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = log.events\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert traces generalized\n",
    "def conv_traces(df):\n",
    "    d = {}\n",
    "    for i in df.columns:\n",
    "        d[i] = ' '.join(df[i].map(str))\n",
    "        \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby('trace_id')[df.columns[df.columns!='trace_id']].apply(conv_traces)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['LMTextList', 'LMLabelList']\n",
    "\n",
    "def label_for_lm(self, **kwargs):\n",
    "    \"A special labelling method for language models.\"\n",
    "    self.__class__ = LMTextList\n",
    "    kwargs['label_cls'] = LMLabelList\n",
    "    return self.label_const(0, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def uniqueify(x, sort=False):\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if sort: res.sort()\n",
    "    return res\n",
    "\n",
    "class Processor():\n",
    "    def process(self, items): return items\n",
    "\n",
    "class CategoryProcessor(Processor):\n",
    "    def __init__(self,default_token=None): \n",
    "        self.vocab=None\n",
    "        self.default_token=default_token\n",
    "\n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            self.vocab = uniqueify(items)\n",
    "            if self.default_token is not None:\n",
    "                for o in reversed(self.default_token):\n",
    "                    if o in self.vocab: self.vocab.remove(o)\n",
    "                    self.vocab.insert(0, o)\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return self.otoi[item]\n",
    "\n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    def deproc1(self, idx): return self.vocab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_numericalize=CategoryProcessor(default_spec_tok)\n",
    "user_numericalize(df['org:resource'])\n",
    "\n",
    "activity_numericalize=CategoryProcessor(default_spec_tok)\n",
    "activity_numericalize(df['concept:name']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 821 Âµs, total: 2.78 s\n",
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def create_traces(df):\n",
    "    ll=[]\n",
    "    trace_ids=[]\n",
    "    for n, g in df.groupby('trace_id'):\n",
    "        ea=activity_numericalize(g['concept:name'])\n",
    "        eu=user_numericalize(g['org:resource'])\n",
    "        ll.append([ea,eu])\n",
    "        trace_ids.append(n)\n",
    "\n",
    "    df2=pd.DataFrame(ll,columns=[\"Activities\",'Users'])\n",
    "    df2.index=trace_ids\n",
    "    return df2\n",
    "\n",
    "data=create_traces(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activities</th>\n",
       "      <th>Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>[8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 11,...</td>\n",
       "      <td>[8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 9, 9, 9, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173691</th>\n",
       "      <td>[8, 9, 10, 11, 11, 11, 11, 12, 14, 13, 15, 16,...</td>\n",
       "      <td>[8, 8, 8, 8, 9, 9, 9, 10, 10, 10, 10, 10, 9, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173694</th>\n",
       "      <td>[8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12,...</td>\n",
       "      <td>[8, 8, 8, 8, 16, 16, 9, 9, 17, 17, 17, 17, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173697</th>\n",
       "      <td>[8, 9, 26]</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173700</th>\n",
       "      <td>[8, 9, 26]</td>\n",
       "      <td>[8, 8, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Activities  \\\n",
       "173688  [8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 11,...   \n",
       "173691  [8, 9, 10, 11, 11, 11, 11, 12, 14, 13, 15, 16,...   \n",
       "173694  [8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12,...   \n",
       "173697                                         [8, 9, 26]   \n",
       "173700                                         [8, 9, 26]   \n",
       "\n",
       "                                                    Users  \n",
       "173688  [8, 8, 8, 8, 9, 10, 10, 10, 10, 10, 9, 9, 9, 9...  \n",
       "173691  [8, 8, 8, 8, 9, 9, 9, 10, 10, 10, 10, 10, 9, 9...  \n",
       "173694  [8, 8, 8, 8, 16, 16, 9, 9, 17, 17, 17, 17, 17,...  \n",
       "173697                                          [8, 8, 8]  \n",
       "173700                                          [8, 8, 8]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(np_arr,train=0.9):\n",
    "    shuffle = np_arr[np.random.permutation(len(np_arr))]\n",
    "    split = int(len(np_arr)*0.9)\n",
    "    train, valid = shuffle[:split], shuffle[split:]\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = random_split(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([8, 9, 28, 28, 28, 28, 28, 28, 10, 11, 28, 11, 11, 11, 11, 11, 11, 11, 26, 11]),\n",
       "        list([8, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 16, 20, 20, 16, 16, 16, 16, 16])],\n",
       "       [list([8, 9, 26]), list([8, 8, 8])],\n",
       "       [list([8, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 14, 13, 15, 16, 17, 11, 17, 18, 19, 17]),\n",
       "        list([8, 8, 8, 8, 75, 75, 41, 41, 65, 65, 17, 17, 17, 17, 17, 17, 17, 17, 28, 28, 28, 28])],\n",
       "       [list([8, 9, 26]), list([8, 8, 8])],\n",
       "       [list([8, 9, 10, 11, 11, 11, 11, 27, 11]),\n",
       "        list([8, 8, 8, 8, 18, 18, 34, 34, 34])]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blicke ich nicht durch\n",
    "\n",
    "class PPDataSet():\n",
    "    def __init__(self, activities,users, bs=64, bptt=70, shuffle=False):\n",
    "        self.data,self.bs,self.bptt,self.shuffle = data,bs,bptt,shuffle\n",
    "        total_len = sum([len(t) for t in data])\n",
    "        self.n_batch = total_len // bs\n",
    "        self.a_batched=self.batchify(activities)\n",
    "        self.u_batched=self.batchify(users)\n",
    "\n",
    "    \n",
    "    def __len__(self): return ((self.n_batch-1) // self.bptt) * self.bs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        a_source = self.a_batched[idx % self.bs]\n",
    "        u_source = self.u_batched[idx % self.bs]\n",
    "\n",
    "        seq_idx = (idx // self.bs) * self.bptt\n",
    "        return ((a_source[seq_idx:seq_idx+self.bptt],u_source[seq_idx:seq_idx+self.bptt]),\n",
    "                 (a_source[seq_idx+1:seq_idx+self.bptt+1],u_source[seq_idx+1:seq_idx+self.bptt+1]))\n",
    "    \n",
    "    def batchify(self,d):\n",
    "        texts = d\n",
    "        if self.shuffle: texts = texts[torch.randperm(len(texts))]\n",
    "        stream = torch.cat([torch.cat((tensor([2]),tensor(t),tensor([3]))) for t in texts])\n",
    "        return stream[:self.n_batch * self.bs].view(self.bs, self.n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([8, 9, 28, 28, 28, 28, 28, 28, 10, 11, 28, 11, 11, 11, 11, 11, 11, 11, 26, 11]),\n",
       "       list([8, 8, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 16, 20, 20, 16, 16, 16, 16, 16])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7425aea3067e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'activities' is not defined"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(PPDataSet(activities, users, shuffle=False), batch_size=bs)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Embedding(n_in, 7, padding_idx=1),nn.Linear(7,nh), nn.ReLU(), nn.Linear(nh,len(activity_numericalize.vocab))]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "            print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming initialization:\n",
    "nh = 50\n",
    "m = 32 # number of columns in the dataset\n",
    "\n",
    "w1 = torch.randn(m, nh)/math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, 1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0.)\n",
    "def lin(x, w, b): x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c5f0347f8aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-7d6f62ee55e1>\u001b[0m in \u001b[0;36mlin\u001b[0;34m(x, w, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu(lin(train, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(5, 5, batch_first=True)\n",
      ")\n",
      "epoch: 1, loss: 1.722\n",
      "Predicted string: lohhhl\n",
      "epoch: 2, loss: 1.546\n",
      "Predicted string: lollll\n",
      "epoch: 3, loss: 1.422\n",
      "Predicted string: lollll\n",
      "epoch: 4, loss: 1.271\n",
      "Predicted string: ihllll\n",
      "epoch: 5, loss: 1.120\n",
      "Predicted string: ihelll\n",
      "epoch: 6, loss: 0.979\n",
      "Predicted string: ihelll\n",
      "epoch: 7, loss: 0.852\n",
      "Predicted string: ihello\n",
      "epoch: 8, loss: 0.745\n",
      "Predicted string: ihello\n",
      "epoch: 9, loss: 0.679\n",
      "Predicted string: ihello\n",
      "epoch: 10, loss: 0.642\n",
      "Predicted string: ihello\n",
      "epoch: 11, loss: 0.616\n",
      "Predicted string: ihello\n",
      "epoch: 12, loss: 0.597\n",
      "Predicted string: ihello\n",
      "epoch: 13, loss: 0.582\n",
      "Predicted string: ihello\n",
      "epoch: 14, loss: 0.570\n",
      "Predicted string: ihello\n",
      "epoch: 15, loss: 0.560\n",
      "Predicted string: ihello\n",
      "epoch: 16, loss: 0.551\n",
      "Predicted string: ihello\n",
      "epoch: 17, loss: 0.542\n",
      "Predicted string: ihello\n",
      "epoch: 18, loss: 0.533\n",
      "Predicted string: ihello\n",
      "epoch: 19, loss: 0.525\n",
      "Predicted string: ihello\n",
      "epoch: 20, loss: 0.518\n",
      "Predicted string: ihello\n",
      "epoch: 21, loss: 0.511\n",
      "Predicted string: ihello\n",
      "epoch: 22, loss: 0.503\n",
      "Predicted string: ihello\n",
      "epoch: 23, loss: 0.497\n",
      "Predicted string: ihello\n",
      "epoch: 24, loss: 0.493\n",
      "Predicted string: ihello\n",
      "epoch: 25, loss: 0.490\n",
      "Predicted string: ihello\n",
      "epoch: 26, loss: 0.489\n",
      "Predicted string: ihello\n",
      "epoch: 27, loss: 0.489\n",
      "Predicted string: ihello\n",
      "epoch: 28, loss: 0.487\n",
      "Predicted string: ihello\n",
      "epoch: 29, loss: 0.485\n",
      "Predicted string: ihello\n",
      "epoch: 30, loss: 0.482\n",
      "Predicted string: ihello\n",
      "epoch: 31, loss: 0.480\n",
      "Predicted string: ihello\n",
      "epoch: 32, loss: 0.478\n",
      "Predicted string: ihello\n",
      "epoch: 33, loss: 0.477\n",
      "Predicted string: ihello\n",
      "epoch: 34, loss: 0.477\n",
      "Predicted string: ihello\n",
      "epoch: 35, loss: 0.477\n",
      "Predicted string: ihello\n",
      "epoch: 36, loss: 0.476\n",
      "Predicted string: ihello\n",
      "epoch: 37, loss: 0.476\n",
      "Predicted string: ihello\n",
      "epoch: 38, loss: 0.476\n",
      "Predicted string: ihello\n",
      "epoch: 39, loss: 0.475\n",
      "Predicted string: ihello\n",
      "epoch: 40, loss: 0.474\n",
      "Predicted string: ihello\n",
      "epoch: 41, loss: 0.473\n",
      "Predicted string: ihello\n",
      "epoch: 42, loss: 0.472\n",
      "Predicted string: ihello\n",
      "epoch: 43, loss: 0.471\n",
      "Predicted string: ihello\n",
      "epoch: 44, loss: 0.471\n",
      "Predicted string: ihello\n",
      "epoch: 45, loss: 0.470\n",
      "Predicted string: ihello\n",
      "epoch: 46, loss: 0.470\n",
      "Predicted string: ihello\n",
      "epoch: 47, loss: 0.470\n",
      "Predicted string: ihello\n",
      "epoch: 48, loss: 0.469\n",
      "Predicted string: ihello\n",
      "epoch: 49, loss: 0.469\n",
      "Predicted string: ihello\n",
      "epoch: 50, loss: 0.469\n",
      "Predicted string: ihello\n",
      "epoch: 51, loss: 0.468\n",
      "Predicted string: ihello\n",
      "epoch: 52, loss: 0.468\n",
      "Predicted string: ihello\n",
      "epoch: 53, loss: 0.467\n",
      "Predicted string: ihello\n",
      "epoch: 54, loss: 0.467\n",
      "Predicted string: ihello\n",
      "epoch: 55, loss: 0.467\n",
      "Predicted string: ihello\n",
      "epoch: 56, loss: 0.467\n",
      "Predicted string: ihello\n",
      "epoch: 57, loss: 0.466\n",
      "Predicted string: ihello\n",
      "epoch: 58, loss: 0.466\n",
      "Predicted string: ihello\n",
      "epoch: 59, loss: 0.466\n",
      "Predicted string: ihello\n",
      "epoch: 60, loss: 0.466\n",
      "Predicted string: ihello\n",
      "epoch: 61, loss: 0.465\n",
      "Predicted string: ihello\n",
      "epoch: 62, loss: 0.465\n",
      "Predicted string: ihello\n",
      "epoch: 63, loss: 0.465\n",
      "Predicted string: ihello\n",
      "epoch: 64, loss: 0.465\n",
      "Predicted string: ihello\n",
      "epoch: 65, loss: 0.464\n",
      "Predicted string: ihello\n",
      "epoch: 66, loss: 0.464\n",
      "Predicted string: ihello\n",
      "epoch: 67, loss: 0.464\n",
      "Predicted string: ihello\n",
      "epoch: 68, loss: 0.464\n",
      "Predicted string: ihello\n",
      "epoch: 69, loss: 0.464\n",
      "Predicted string: ihello\n",
      "epoch: 70, loss: 0.463\n",
      "Predicted string: ihello\n",
      "epoch: 71, loss: 0.463\n",
      "Predicted string: ihello\n",
      "epoch: 72, loss: 0.463\n",
      "Predicted string: ihello\n",
      "epoch: 73, loss: 0.463\n",
      "Predicted string: ihello\n",
      "epoch: 74, loss: 0.463\n",
      "Predicted string: ihello\n",
      "epoch: 75, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 76, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 77, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 78, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 79, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 80, loss: 0.462\n",
      "Predicted string: ihello\n",
      "epoch: 81, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 82, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 83, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 84, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 85, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 86, loss: 0.461\n",
      "Predicted string: ihello\n",
      "epoch: 87, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 88, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 89, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 90, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 91, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 92, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 93, loss: 0.460\n",
      "Predicted string: ihello\n",
      "epoch: 94, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 95, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 96, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 97, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 98, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 99, loss: 0.459\n",
      "Predicted string: ihello\n",
      "epoch: 100, loss: 0.459\n",
      "Predicted string: ihello\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "\n",
    "# Teach hihell -> ihello\n",
    "x_data = [0,1,0,2,3,3] # hihell\n",
    "y_data = [1,0,2,3,3,4] # ihello\n",
    "\n",
    "# one hot encoding \"hello\":\n",
    "one_hot = [[1,0,0,0,0],    # h\n",
    "           [0,1,0,0,0],    # i\n",
    "           [0,0,1,0,0],    # e\n",
    "           [0,0,0,1,0],    # l\n",
    "           [0,0,0,0,1]]    # o\n",
    "\n",
    "x_one_hot = [one_hot[x] for x in x_data]\n",
    "\n",
    "# As we have one batch of samples, we will change them to variables only once\n",
    "inputs = autograd.Variable(torch.Tensor([x_one_hot]))\n",
    "labels = autograd.Variable(torch.LongTensor(y_data))\n",
    "\n",
    "num_classes = 5\n",
    "input_size = 5  # one-hot size\n",
    "hidden_size = 5  # output from the LSTM. 5 to directly predict one-hot\n",
    "batch_size = 1   # one sentence\n",
    "sequence_length = 6  # |ihello| == 6\n",
    "num_layers = 1  # one-layer rnn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size=5, hidden_size=5, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
    "        hidden_0 = autograd.Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        # Reshape input\n",
    "        x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "\n",
    "        # Propagate input through RNN\n",
    "        # Input: (batch, seq_len, input_size)\n",
    "        # hidden_0: (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x, hidden_0)\n",
    "        return out.view(-1, num_classes)\n",
    "\n",
    "\n",
    "# Instantiate RNN model\n",
    "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
    "print(rnn)\n",
    "\n",
    "# Set loss and optimizer function\n",
    "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    outputs = rnn(inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data.item()))\n",
    "    print(\"Predicted string:\", ''.join(result_str))\n",
    "\n",
    "print(\"Learning finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0515, -0.8492],\n",
      "         [ 0.2795, -0.9419],\n",
      "         [ 0.4416, -0.8957],\n",
      "         [ 0.4098, -0.8876],\n",
      "         [-0.6697, -0.9033]],\n",
      "\n",
      "        [[ 0.8689, -0.2063],\n",
      "         [ 0.5361, -0.7273],\n",
      "         [ 0.4454, -0.8597],\n",
      "         [-0.6698, -0.8994],\n",
      "         [-0.0468, -0.9692]],\n",
      "\n",
      "        [[ 0.5448, -0.8665],\n",
      "         [ 0.0948, -0.9403],\n",
      "         [-0.3374, -0.9686],\n",
      "         [ 0.5992, -0.9051],\n",
      "         [-0.7109, -0.9037]]])\n"
     ]
    }
   ],
   "source": [
    "# input dimension 4 --> output dimension 2\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)\n",
    "\n",
    "# one letter input\n",
    "inputs = autograd.Variable(torch.Tensor([[h,e,l,l,o],\n",
    "                                         [e,l,l,o,h],\n",
    "                                         [l,e,h,l,o]]))\n",
    "\n",
    "# initializing the hidden state:\n",
    "# (num_layers * num_directions, batch_size, hidden_size)\n",
    "# in this case: only 1 layer and 1 direction, 1 batch and a hidden_size or output_size of 2\n",
    "hidden = autograd.Variable(torch.randn(1,3,2))\n",
    "\n",
    "# feeding one letter at a time\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(out.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Anderer Versuch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "from torch import autograd\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [0,1,0,2,3,3] # hihell\n",
    "y_data = [1,0,2,3,3,4] # ihello\n",
    "\n",
    "# one hot encoding \"hello\":\n",
    "one_hot = [[1,0,0,0,0],    # h\n",
    "           [0,1,0,0,0],    # i\n",
    "           [0,0,1,0,0],    # e\n",
    "           [0,0,0,1,0],    # l\n",
    "           [0,0,0,0,1]]   # o\n",
    "\n",
    "x_one_hot = [one_hot[x] for x in x_data]\n",
    "\n",
    "inputs = autograd.Variable(torch.Tensor([x_one_hot]))\n",
    "labels = autograd.Variable(torch.Tensor(y_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "num_classes = 5\n",
    "input_size = 5\n",
    "hidden_size = 5\n",
    "batch_size = 1\n",
    "sequence_length = 6\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # Reshape input into this size (bs, sl, is)\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # Propagate input through RNN\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.view(-1, num_classes)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        return autograd.Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "model = Model()\n",
    "\n",
    "metric = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden()\n",
    "    outputs = model(inputs, hidden)\n",
    "    loss = metric(outputs[0], labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, idx = outputs.max(1)\n",
    "    idx = idx.data.numpy()\n",
    "    result_str = [idx2char[c] for c in idx.squeeze()]\n",
    "    print(\"epoch: %d, loss: %1.3f\" % (epoch + 1, loss.data.item()))\n",
    "    print(\"Predicted string:\", ''.join(result_str))\n",
    "\n",
    "    # sys.stdout.write(\"predicted string: \")\n",
    "    # for input, label in zip(inputs, labels):\n",
    "    #     hidden, output = model(input, hidden)\n",
    "    #     val, idx = output.max(1)\n",
    "    #     sys.stdout.write(idx2char[idx.data[0]])\n",
    "    #     loss += metric(output, label)\n",
    "\n",
    "    # print(', epoch: %d, loss: %1.3f' % epoch+1, loss.data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastpm2",
   "language": "python",
   "name": "fastpm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
